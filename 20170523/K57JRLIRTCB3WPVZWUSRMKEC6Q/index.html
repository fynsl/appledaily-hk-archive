<html><header><meta charset="utf-8"><title>審查準則首曝光fb未禁絕自殘　色情內容</title></header><body><h1>審查準則首曝光<br>fb未禁絕自殘　色情內容</h1><p>社交媒體霸主facebook的內容審查準則，首次曝光。英國《衞報》取得fb發給內容過濾員超過100份內部指引及守則，指fb未有完全禁止色情、欺凌和暴力的內容，除非是令人極度不安，用戶是容許分享虐童、虐畜圖片，甚至是直播意圖自殺的行為。外洩文件再次引起外界關注，影響力越來越大的社交媒體，如何平衡道德操守和言論自由。<br>擁有約20億用戶的fb，過去從未披露其過濾內容的準則，今次內部文件曝光可讓外界一窺全豹，可見fb對暴力內容、仇恨言論、恐怖主義、色情、種族主義、比賽造假、人食人等有爭議內容，都有審查指引。目前，fb僱用了4,500位內容過濾員，應付海量的可疑報告，單是處理假賬戶每周便多達650萬宗。<br>由於工作繁重，過濾員只有10秒時間來決定可疑內容去留，《衞報》引述一知情人士指情況已有點失控：「facebook根本控制不了其內容，因為它增長得太大太快。」亦有過濾員批評，部份指引前後矛盾，令他們難以適從。</p><p>國家元首列受保護範圍</p><p>根據fb內部守則，內容出現「有人要槍擊特朗普」等字眼要即刪，理由是特朗普是國家元首，列入受保護範圍。可是，用戶寫「想咬斷婊子頸項，必須要在喉嚨中間位置狠狠用力」卻可以過關，原因是fb不認為這構成確切威脅。其中一份文件更清楚列明，fb容許用戶「使用激烈的語言在網上表達挫折感」。<br>近期接連有人利用fb直播殺人、強姦或自殺，惹來廣泛抨擊，歐美兩地政府都有聲音要求將fb納入傳統媒體的監管範圍。<br>fb顯然是在負起道德責任和避免成為一副言行審查機器之間拉扯，例如內部文件解釋，不移除用戶自殘內容的原因，是希望引起外界關注，阻止悲劇發生，fb視「用戶張貼自殘內容是哭着求救的表現，刪掉內容無疑令用戶求救無門」。</p><p>指公眾有知情權</p><p>fb全球政策管理主管比克特，為平台常常出現令人不安的片段辯護，認為部份有新聞價值，公眾有權知道，她說：「舉個例子，假如在2001年9月11日，旁觀者用fb直播世貿雙子塔上有人躍下的片段，我們在當時及事後也不會移除內容……對於有人上載關於自殘或自殺內容，我們是希望他們的親友可以提供協助。」<br>英國《衞報》</p><p>部份審查例子</p><p>暴力死亡片段：不一定要刪走，但須標記會令人不安<br>暴力及虐童圖片：毋須移除，除非含色情或涉及名人<br>烹狗圖片：可以分享，但須標記會令人不安<br>白人至上的3K黨人畫像：移除<br>手繪性愛圖片：可以分享<br>數碼製造描述性愛活動圖片：不可以分享<br>納粹大屠殺有裸體的歷史照：可以分享<br>墮胎片段：可以分享，但不准有裸露成份<br>直播自殘：可以，fb不希望審查處於困難的人<br>留言「我想找人幹掉你」：視為發洩情緒，不視為確切威脅，可保留<br>留言「有人槍擊特朗普」：移除，因為特朗普是國家元首<br>留言「去毆打這群肥仔」：可以分享<br>未經同意分享別人私影裸照：移除<br>指特朗普是納粹分子：可以分享<br>展示槍械圖片：可以分享<br>拉登圖片：移除<br>血腥的玩具圖片：可以分享<br>美軍虐囚圖片：可以分享<br>死者棺材照：可以分享<br>納粹畫報：移除<br>詛咒留言：可以分享<br>資料來源：英國《衞報》</p></body></html>