<html><header><meta charset="utf-8"><title>【iPhone XS實測】A12跑分大勝iPhone X　拆解關鍵技術神經網絡引擎</title></header><body><h1>【iPhone XS實測】A12跑分大勝iPhone X　拆解關鍵技術神經網絡引擎</h1><p>iPhone XS在發佈會中用A12 Bionic處理器做重點，部份果迷覺得追機能、不講創意， 沒有Apple風格，但A12除了效能強大，還有不少值得留意的地方。它是全球第一顆量產的7nm製程處理器，華為的Kirin 980雖早一步發表，但預計10月才有手機採用。Apple作為一間不是以處理器為主要業務的公司，能搶先過Intel、Qualcomm等大廠，當然值得作為賣點宣傳。</p><p>比起A11的10nm，更細的7nm製程能在相同體積尺寸下放入更多電晶體，令處理器的效能更強亦更省電。我們以《Antutu評測》和《Geekbench》兩個app跑分，iPhone XS和XS Max能在Antutu跑出26萬分，iPhone X是18萬。在測試CPU效能的Geekbench中，XS兩機單核效能為4,800分，X則是4200分；多核效能方面，XS為11,000分，X則是10,400分。跑分成積有明顯差距。官方指A12的2大4小的6核CPU比A11速度提升15%，減少能源消耗50%；而GPU方面則比A11多1核，用上4核心，速度提升50%。</p><p>而A12強大的秘密還在於神經網絡引擎。這引擎在A11首度配備，每秒可運行6千億次計算。來到A12，則大幅提升約9位，達到每秒運行 5 萬億次計算。神經網絡引擎是專門針對AI工作的深度學引擎，iPhone X推出時，主要用在人臉識辨和Face ID之上。這次A12在發佈會上更強調另一工作「機械學習」（Machine Learning）。機械學習是靠分析大量資料做演算，以Face ID為例，登錄時用家要轉臉部一個圈 ，就是記錄不同角度的相片資料，從而分析出用家的臉部外形。</p><p>透過A12更強大的機械學習功能，Apple用大量相片資料教懂iPhone XS和XR相機分辨拍攝主體，所以做到更強大的模擬景深調節效果。而新的Smart HDR功能也是靠神經網絡做一兆次運算。第一步相機先以零時滯拍下4張連拍，再透過程式將這4格相片中複製出不同曝光設定的版本，最後再由神經網絡挑選各版本中最好的部份，合成出最終成像。比起單純的以連拍合成的HDR效果，Smart HDR不只合成，還會挑走不合適的相片和懂得局部挑選相片值得保留的部份，效果更出色之餘，也更有利於拍攝過往HDR較難捕捉的動態物件。<br></p><p>發佈會中亦多次提到Apple自家的機械學習框架Core ML2的更新和新iPhone的實時機械學習能力，在籃球訓練app 《HomeCourt》的示範中，開發人員馬景輝表示，只有iPhone X可即時分析到球員的射波姿勢和數據。另外AR遊戲《Galaga AR》能夠讓3名玩家同時分享同一個AR遊戲場景，估計也是得益於A12神經網絡引擎的強大空間辨識功能。<br><br>說了這麼多，A12 Bionic正如其中文名「A12仿生」所說，是專為AI而設。AI在科技界是目前的當紅炸子雞，在科研層面也的確帶來了很大的革新，但能否應用到手機消費者層面，就要看未來app開發者的功力了。<br><br>記者：韓繼聰<br>攝影：伍慶泉<br><br>********<br>據聞SmarTone今年貨量同上年一樣係最多，新機實快到手啦！要發揮出全新iPhone嘅更強性能，當然要配合SmarTone超強勢網絡，即上 http://bit.ly/2OdqbkE  訂購啦！<br></p></body></html>