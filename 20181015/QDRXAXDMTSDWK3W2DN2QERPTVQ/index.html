<html><header><meta charset="utf-8"><title>人類料長遠無法駕馭AI</title></header><body><h1>人類料長遠無法駕馭AI</h1><p>「超級人工智能（AI）的到來，可以是對人類來說最好的事，也可成為最壞的事。」霍金在遺作涉獵到AI議題，他指當受制於緩慢生物進化的人類，無法駕馭具無限發展潛能的AI，我們將面對極大風險。</p><p>電腦出事　道指閃崩跌千點</p><p>霍金形容，擁有高智慧的AI不再是科幻故事的情節；藉此科技，人類有機會享受一個免受疾病貧窮侵擾的未來。而AI亦將可不依靠人類輔助，以循環提升形式自我完善，令其智慧超越人類的能力。但霍金警告，在AI超越人類的一刻來臨時，我們必須確保AI與人類站在同一陣線，否則AI或會轉向對抗人類。<br>霍金舉例指出，如近年各國國防考慮展開自主武器的軍備競賽。自主武器可以在無人干預下，識別並攻擊目標，趨勢惹他擔憂，並反問：「當人類對能否長遠控制先進的AI，仍尚存憂慮，我們又應否用它來武裝自己，或把國防交給它呢？」他又提起，美股2010年因電腦操盤交易系統問題發生閃崩（Flash Crash），令道指在數分鐘內暴跌近1,000點，「若此由電腦觸發的崩潰，發生在軍事舞台上會是怎樣呢？」<br>他強調，「短期來說，AI的影響是基於誰控制它；長期來說，AI的影響是基於是否能控制它」。因此，他及SpaceX創辦人馬斯克，皆同一眾AI專家提倡認真研究AI對社會的影響，「我們的未來是一場競賽，是日漸強大的科技與我們掌握它的智慧之間的比賽，要確保我們的智慧取勝」。<br>英國《星期日泰晤士報》</p></body></html>