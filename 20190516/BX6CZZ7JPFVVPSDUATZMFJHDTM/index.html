<html><header><meta charset="utf-8"><title>亞馬遜軟件涉「膚色歧視」</title></header><body><h1>亞馬遜軟件涉「膚色歧視」</h1><p>獲美國警方和海關採用的亞馬遜（Amazon）公司面容識別軟件「Rekognition」，被揭發在辨別深膚色女性時，出錯率高達31%，深層原因更可能涉及敏感的科技歧視。</p><p>黑人議員標注為罪犯</p><p>美國麻省理工學院及加拿大多倫多大學的聯合研究發現，Rekognition認錯深膚色女性為男人的機會高達31%。相反，在識別淺膚色女性時，遇到同樣情況就只有7%。研究人員質疑Rekognition配對白人或男士的準繩度較高，背後或與這套人工智能軟件在開發時，科學家應用了涉及種族及性別歧視的演算法。去年，美國公民自由聯盟曾利用Rekognition掃描國會議員的相片，多位黑人議員竟被標注為罪犯。<br><br>人權組織批評，有色人種在美國被警方截查的機會本來就特別高，若執法機關再使用會「點錯相」的面容識別軟件，拉錯人的可能性便會隨之增加。不過，亞馬遜反駁麻省理工及多倫多大學分析其軟件的方法有錯，又指研究在去年8月開始，公司後來已對Rekognition進行了軟件更新，修正相關錯誤。<br>VOX網站</p></body></html>