<html><header><meta charset="utf-8"><title>fb︰鬧「警狗」「曱甴」不違守則</title></header><body><h1>fb︰鬧「警狗」「曱甴」不違守則</h1><p>【本報訊】自反送中運動爆發以來，從現實生活到社交媒體罵戰不斷，一邊有人指罵警察為「狗」，而警察及撐警人士則不斷辱罵示威者是「曱甴」。然而，facebook指出，按facebook「社群守則」，該類非人化的言論雖屬於仇恨言論，但不一定會被移除，會視乎情況考慮。另facebook屢遭質疑政治審查，刪去或不能發佈與警暴相關的貼文，facebook指不能發佈相關影片或與技術問題有關。<br>記者︰李雨夢<br><br>facebook亞太區公共政策經理Simon Harari接受傳媒訪問時表示，facebook今年第三季共移除700萬篇含仇恨言論的貼文，其中有80%是在社群檢舉前已被facebook主動發現；含欺凌和騷擾的貼文上季有320萬篇被移除，但只有16.1%是由facebook主動發現。他指出，由於這些貼文非常需要了解脈絡才能作決定，故較為需要依賴社群檢舉，現時facebook共有15,000名專職的內容審查員遍佈全球，審查所涵蓋的語言包括廣東話。</p><p>警察示威者不屬受保護特徵</p><p>列舉仇恨言論的例子時，Simon Harari指，若言論是針對種族、族裔、國籍、宗教、性傾向、社會地位、性別、性別認同、重大疾病或身心障礙等所謂的保障特徵進行攻擊，facebook會移除貼文。他以兩則辱罵示威者為「曱甴」及辱罵警察為「狗」的貼文為例，指兩則貼文都以非人化手法作出攻擊，屬於仇恨言論，但由於警察是職業、示威者亦不屬以上的受保護特徵時，原則上沒有違反社群守則，但坦言會視乎不同情況，處理不同貼文是否需被移除。<br><br>外界有指未能於社交網站上發佈與警暴有關的資訊，Simon Harari直言沒有使用人工智能（AI）阻止影片的發佈，有可能是涉及技術性問題，需要再作調查才能確定影片未能發佈的原因。就警員被起底的情況，他指保障個人私隱乃facebook最基本的價值，故若出現資料外洩情況亦會刪除有關貼文，另外基於保護兒童的原則下，有警員家屬的資料及相片被公開，若確定有潛在威脅時，facebook亦會嘗試阻止相關事情發生。</p></body></html>