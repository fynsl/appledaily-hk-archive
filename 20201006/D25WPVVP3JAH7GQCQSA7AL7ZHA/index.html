<html><header><meta charset="utf-8"><title>#decentralizehk●以垃圾餵食的AI，輸出的也將是垃圾</title></header><body><h1>#decentralizehk●以垃圾餵食的AI，輸出的也將是垃圾</h1><p>上期提到，當TikTok的演算法應用在新聞，再加上背後對極權政府的高度配合，會演化成最中心化的新聞篩選。文章刊出後，收到一些頗為典型的意見，說責任不是出在工具而在人。</p><p>我自己也從事科技，也常說類似的話，但差之毫釐：所謂責任在人是指使用應用科技的人，比如砍人案的問題不在刀而在罪犯。放在AI篩選新聞的語境，那是應用開發商與運營商，有人卻曲解為讀者與公眾。持這種論述的，要不就是樂於把責任一記推向受眾，要不就是自視過高，而我兩種都遇過。讀者固然應該保持批判，有責任提升媒體素養，但以為個人可以在資訊大海裏每天靠着AI去挑選內容而不受演算法左右，根本沒有認清形勢。</p><p>2015年，AlphaGo打敗世界頂尖圍棋高手成為一時佳話，到了現在，這種AI在特定領域戰勝全人類的事情已成常識，有人戰勝AlphaGo才是新聞。事件中有個細節：AlphaGo的某些下子，任何高手都摸不着頭腦，換言之，人類沒法理解它的決定，但結果證明它是對的。</p><p>有人會說那很好，那代表它比人類聰明。圍棋你可以這樣說，那駕駛呢？司機不知道自動駕駛為何轉向，總之相信那是為了安全就好？醫療判斷呢？新聞篩選呢？顯然，即使AI多強大，假如它無法向人類解釋抉擇，在某些使用場景會產生倫理問題。針對這點，有人倡議XAI，eXplainable Artificial Intelligence，可以預計，先進國如歐盟會朝這個方向立法。不過，面對龐大商機，人類發展AI的速度，只會越來越拋離立法規管AI的速度，直至發生重大災難。</p><h2>AI選新聞　有興趣但不見得重要</h2><p>AI有兩個不可或缺的元素，一是機器學習，一是明確目標。定義目標，比如照片分類，再給機器提供大量數據，如人類分類好的一百億照片，機器就能一定程度上學會照片分類。數據量越多、質越高，目標越明確，機器學習的效果越好。特定領域如圍棋，AI最先超越人類，因為目標最明確，數據量大質高；中國可能在AI全球領先，因為該國私隱意識和法理保障都全球領先地弱。</p><p>現在越來越少聽到了，傳統新聞工作者一個很重要的角色，是議題設定，即決定甚麼重要，甚麼不是。重要很多時並不符合直覺，比如在70年代談環保、80年代談本土，或者這個年代談AI的弊病。</p><p>最重要的議題，傳媒會報道並放A1，次要的也會報道但放內頁，不關痛癢的則無視掉。你或說，這不是廢話嗎？我但願是，可惜這些本是常識的廢話已經失效，現在越多人看的媒體，越不是以重要性為議題設定的基礎。不同意的，請打開面書、TikTok，看看第一個出現的story。</p><p>不妨推後一步，看看「making of」。篩選和排序新聞的應用，機器學習的數據採樣並非頂尖編輯每天選甚麼A1（對應頂尖棋手怎麼下棋），而是用戶是否讚好、有否留言互動、閱讀多久，甚至盯着屏幕哪部份（讀到前置鏡頭就能計算你的眼球軌迹），走着、停着還是躺着看（讀到感應器就知道）等，數據力量和幻想，會嚇你一跳。一切學習，指往一個目標：你是否有興趣。</p><p>三言兩語重複，純AI篩選新聞是甚麼回事：AlphaGo般厲害的AI透過大量數據把自己培訓得爐火純青，「以人為本」地每刻為你挑選最感興趣，但不見得重要的新聞。</p><p>撰文：高重建</p><p>地球人。信仰民主自由。創業者。LikeCoin、#decentralizehk 發起人。</p></body></html>