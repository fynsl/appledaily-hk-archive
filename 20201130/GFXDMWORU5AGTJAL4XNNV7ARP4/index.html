<html><header><meta charset="utf-8"><title>高頻數據密度高　處理技術要求大增</title></header><body><h1>高頻數據密度高　處理技術要求大增</h1><p>常聽財演說高頻交易，但實際真的能處理高頻數據的人不多，因為使用高頻數據存在技術困難。首先是處理的資料量大增，正常的日數據，每年只有200多個數據點，對於運算能力要求比較低。對比之下，一分鐘數據的資料總量是日數據的幾百倍，每一日的正價交易時段已經有接近400個數據點，因此資料量已經是低頻數據的400倍以上（見圖二），如果計入開市前及收市後時段，數據量進一步提升。更遑論每單交易數據（tick data）或者是買賣盤數據（bid ask data）等等，這類數據密度更高。</p><h2>Excel表或吃不消</h2><p>一般免費的網站只提供日數據，例如Yahoo Finance，就算有提供分鐘數據，也可能只限過去數日之內，總時間長度太短導致不能用於回測。不少網站雖然不支援直接以Excel表下載高頻數據，但卻允許透過API下載，網站Alphavantage就提供了API下載過去兩年的分鐘ohlcv數據。據筆者了解，很多網上券商，例如是盈透（Interactive Brokers）或是富途，都支持使用API下載，但可能設有流量限制。而且，試想像長達兩年的一分鐘高頻數據，假設每日正股交易時段大約有400個一分鐘收市價，兩年就有大約20萬個數據點，如果是ohlcv完整格式，一隻股票的分鐘數據已經超過100萬數據點，普通的Excel表通常不能容納這種數據量，就算可以，程式也會變得非常緩慢，動不動就當機，更遑論快速做回測了。</p><p>如果真的有興趣研究高頻數據，筆者也會建議學習使用數據庫（database），因為高頻數據體積龐大，如果每次也重新下載，會嚴重拖慢實驗進度。下載一次後儲存於本機數據庫，待數據有更新才重新下載，可以節省大量讀寫時間。無論如何，從前用戶只能付出昂貴價錢向交易所買入高頻數據，隨着網絡普及，目前已有更多免費的高頻數據資源，券商也發展出更容易使用的API，相關的編程教學也越來越容易入手，有助打破只有專業投資者才可接觸高頻數據的壟斷局面。</p></body></html>